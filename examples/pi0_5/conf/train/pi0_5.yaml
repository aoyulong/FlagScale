system:
  batch_size: 1
  train_steps: 100000
  log_freq: 10
  grad_clip_norm: 1.0
  use_amp: false
  shuffle: false
  num_workers: 4

  optimizer:
    name: AdamW
    lr: 2.5e-5
    betas: [0.9, 0.95]
    eps: 1.0e-8
    weight_decay: 0.01

  scheduler:
    warmup_steps: 1000
    decay_steps: 30000
    decay_lr: 2.5e-6

  checkpoint:
    output_directory: ${experiment.exp_dir}/ckpt
    # Whether to save checkpoint
    save_checkpoint: true
    # Number of steps between checkpoints
    save_freq: 1000
  # TODO(yupu): Support resuming from checkpoint

model:
  model_name: pi0.5
  # Path to the pretrained pi05_base model checkpoint
  checkpoint_dir: /workspace/models/lerobot/pi05_base
  # Path to paligemma tokenizer
  tokenizer_path: /workspace/models/google/paligemma-3b-pt-224
  tokenizer_max_length: 200
  action_steps: 50

data:
  # Path to the training data
  data_path: /workspace/datasets/lerobot/aloha_mobile_cabinet
  tolerance_s: 0.0001
  use_imagenet_stats: true
  # To match the input features naming from the dataset to the policy config
  # For example, for the aloha_mobile_cabinet dataset, the rename_map is:
  rename_map:
    observation.images.cam_high: observation.images.base_0_rgb
    observation.images.cam_left_wrist: observation.images.left_wrist_0_rgb
    observation.images.cam_right_wrist: observation.images.right_wrist_0_rgb
  # By default, Pi0.5 uses quantiles for state and action normalization, if false, it uses mean and std instead
  use_quantiles: false
